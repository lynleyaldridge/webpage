---
title: "Experimenting with SQL in RMarkdown: SELECT, UPDATE and JOIN queries using RSQLite"
author: Lynley Aldridge
date: '2021-01-13'
slug: experimenting-with-sql
categories: []
tags: 
- Rstats
- Tutorial
- SQL
- TidyTuesday
subtitle: ''
output:
  blogdown::html_page:
    toc: true
summary: ''
authors: []
lastmod: '2021-01-17T21:05:19+11:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

In this post I talk through, step-by-step, a process I've been using to document the SQL learning I've been doing using R Markdown. I draw on a tutorial by Andrew Couch to create a database I can manipulate using RSQLite, using a Tidy Tuesday dataset featuring Taylor Swift and Beyoncé album data.  I then run some example SQL queries using this data.

# Introduction

I've been wanting to document some SQL learning I've been doing lately, and was grateful to find a you tube tutorial from Andrew Couch. Here he talks through how to connect to a database using R Studio and query this database using SQL (from within an R Markdown document). In this tutorial I follow his process to add csv data into a simple SQL database and run some queries, to document my own SQL learning journey.

{{< youtube zAgTlZUugUE >}}

# Setup

## Load packages

Let's start by loading packages. First, install any packages not previously used by typing the following command directly into the console (to install odbc, for example): `install.packages("odbc")`

Then run the following.

```{r loadpackages, message = FALSE}
library(tidyverse)
library(odbc)
library(DBI)
library(RSQLite)
```

## Load data

Next, we need to load in our data. I've been wanting to experiment with the [Tidy Tuesday dataset containing Taylor Swift and Beyoncé song lyrics and album details](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-09-29/readme.md) for a while. This is easy to download directly from the Internet, and looks like it would have some promise for practicing SQL. So let's try using the album sales and chart datasets for this exercise.

```{r loaddata, message = FALSE}

sales <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/sales.csv')

charts <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/charts.csv')
```

Taylor Swift data comes from [Taylor Swift albums discography](https://en.wikipedia.org/wiki/Taylor_Swift_albums_discography).

Beyoncé data comes from [Beyoncé discography](https://en.wikipedia.org/wiki/Beyonc%C3%A9_discography).

## Create database

Let's create a connection to a SQLite database, store it in memory, and copy the sales and charts data into this database.

```{r database}
con <- dbConnect(RSQLite::SQLite(), ":memory:")
copy_to(con, sales)
copy_to(con, charts)

```

# SQL queries in R Markdown (an introduction using sales data)

## SELECT query to retrieve all records 

The following code opens the connection to our database, as specified previously, and runs a simple SQL query to SELECT the first five (specified) columns of the sales table. 

```{r}
dbGetQuery(con, '
SELECT artist, title, country, sales, released
FROM sales
                          ')
```

As shown above, this table contains sales data across multiple countries for albums by Taylor Swift and Beyoncé (a total of 48 observations), along with a character field specifying the release date of each album.  

## UPDATE query using SUBSTR to fix release dates

We can see from the above that the release dates for Beyoncé's *Dangerously in Love* and *B'Day* have both been extracted with superfluous details following the date.  The following UPDATE query changes the released date to only a specified substring (all text preceding a space preceding an opening bracket) WHERE strings contained this character combination.  This took close inspection of the data and a process of trial and error to figure out, drawing on stack overflow contributions by [scaisEdge](https://stackoverflow.com/questions/40708459/update-column-to-remove-everything-before-and-including-a-space-in-sqlite) and [CodeBird](https://stackoverflow.com/questions/22558411/how-to-remove-everything-after-certain-character-in-sql). 

```{r message = FALSE}
dbExecute(con, "
UPDATE sales
SET released = TRIM(SUBSTR(released, 1, INSTR(released, ' (')))
WHERE INSTR(released, ' (')>0; 
                          ")
```

This query has updated 6 records. Let's check to see if the relevant dates have now been repaired.

```{r}
dbGetQuery(con, '
SELECT artist, title, country, sales, released
FROM sales
WHERE title LIKE "%Day" OR TITLE = "Dangerously in Love"
                          ')
```

Now that we have formatted these dates consistently, let's try to extract the last four characters of each string to create a `year_released` column. 

The query below uses the `SUBSTR` function to select only the last four characters of the `released` character field, that will allow us to sort data by artist and year of album release as follows.

```{r}
dbGetQuery(con, '
SELECT artist, title, SUBSTR(released, -4) as year_released
FROM sales
GROUP BY title
ORDER BY artist DESC, year_released ASC
                          ')
```

Note from this section that we use [`dbGetQuery`](https://www.rdocumentation.org/packages/DBI/versions/0.5-1/topics/dbGetQuery) from the DBI package to *query* the database, and [`dbExecute`](https://www.rdocumentation.org/packages/DBI/versions/0.5-1/topics/dbExecute) to *update* records.

## UPDATE query using REPLACE to edit sales country field

While we're updating the data, let's also update the country field to use 'WW' consistently to reflect worldwide sales.

```{r message = FALSE}
dbExecute(con, "
UPDATE sales
SET country = REPLACE(country, 'World', 'WW')
WHERE country = 'World'; 
                          ")
```

The `WHERE country = 'World'` filter in the above is not strictly necessary, but it does mean we get output confirming the number of records that have been modified.

We can use the following query to check worldwide sales data is now being reported consistently:

```{r}
dbGetQuery(con, '
SELECT artist, title, country, sales, SUBSTR(released, -4) as year_released
FROM sales
WHERE country = "World" or country = "WW"
                          ')
```

## SELECT DISTINCT and GROUP By query to identify unique values present

Let's use a SELECT DISTINCT query to find out more about the composition of our data. Grouping by artist and title, we learn we have data for 6 unique albums by Beyoncé (comprising 18 entries), and 8 unique albums by Taylor Swift (comprising 30 entries.)  Each album has between 1-6 rows of associated sales data. 

```{r}
dbGetQuery(con, '
SELECT DISTINCT artist, title, SUBSTR(released, -4) as year_released, count(title) as count
FROM sales
GROUP BY artist, title
ORDER BY artist DESC, year_released ASC
                          ')
```

## SELECT and GROUP_CONCAT to summarise available data

Our first glimpse of the sales data showed that this dataset contained data for worldwide sales as well as for a varying number of individual countries. In the following query, I used `GROUP_CONCAT` to show the countries I had sales data for, alongside a count of these countries, for each album. 

```{r}
dbGetQuery(con, '
SELECT title, SUBSTR(released, -4) as year_released, GROUP_CONCAT(Country) as countries, count(Country) AS country_count 
FROM sales
GROUP BY artist, title
ORDER BY artist DESC, year_released ASC
                          ')
```

This confirms that for almost all albums in our dataset, we have US, UK and worldwide sales data. 

# Working with the charts data and using JOIN to merge tables 

## SELECT query using WHERE ... IN to filter records  

Now, let's view data available from the charts table as a precursor to merging this data with the sales data. This table lists artist, title, chart, and peak chart position for each album, across a number of charts. Based on the review of sales data above, I'm going to extract only results for the US and UK to join to the data in the sales table.  

```{r}
dbGetQuery(con, '
SELECT artist, title, chart, chart_position, released
FROM charts
WHERE chart IN ("US", "UK")
                          ')
```

This gives us 28 rows of chart_position data, for 14 albums, across two countries.

I'm going to manipulate released dates to exclude extraneous characters, as before:

```{r message = FALSE}
dbExecute(con, "
UPDATE charts
SET released = TRIM(SUBSTR(released, 1, INSTR(released, ' (')))
WHERE INSTR(released, ' (')>0; 
                          ")
```

## JOIN query to join tables

Now let's try a simple left join to combine sales and chart position data for each album. This gives all rows in the sales table, and matching rows in the charts table.

```{r}
dbGetQuery(con, '
SELECT charts.artist, charts.title, SUBSTR(charts.released, -4) as released, charts.chart, charts.chart_position as position, sales.sales  
FROM charts
LEFT JOIN sales
ON charts.chart = sales.country and
charts.title = sales.title
WHERE charts.chart IN ("US", "UK")
ORDER BY charts.artist DESC, released ASC
                          ')
```

Note that an inner join would give us 25 rows of data. We would lose the UK row for Taylor Swift's self-titled album released in 2006, and the US and UK rows for Folklore, due to lack of rows with matching country codes in the sales table for these records.  

# Next steps

There are a lot of things I'd like to explore further in my SQL learning journey. How would I use the data in the sales table to calculate the percentage of worldwide sales represented by UK and US sales respectively, for each album?  Can I pivot this data easily, to create a table with a column for US chart position/sales and a column for UK chart position/sales? How do I export this data in a way that makes it easy to generate nice tables and graphs in R Markdown?  

Let these, however, be questions for a future post.

# Finally, remember to disconnect

At the end of this process, best practice is always to disconnect from the database.

```{r}
dbDisconnect(con)
```

# References and additional resources

Here are some references I drew on when preparing this tutorial, and pointers to useful resources for future experimentation with SQL.

* Tips on [Getting Started](https://db.rstudio.com/getting-started/) with databases using R (from RStudio) 

* DBI package documentation for [dbGetQuery](https://www.rdocumentation.org/packages/DBI/versions/0.5-1/topics/dbGetQuery) and [dbExecute](https://www.rdocumentation.org/packages/DBI/versions/0.5-1/topics/dbExecute) 

* [Using the tidyverse with Databases](https://sciencificity-blog.netlify.app/posts/2020-12-12-using-the-tidyverse-with-databases/), a three-part series (from Vebash Naidoo's blog Sciencificity) using Alison Hill's [The Great British Bake Off dataset](https://github.com/apreshill/bakeoff) and dplyr's [starwars dataset](https://dplyr.tidyverse.org/reference/starwars.html)

* [Generating SQL with {dbplyr} and sqlfluff](https://emilyriederer.netlify.app/post/sql-generation/) from Emily Riederer - an example using the [palmer penguins dataset](https://allisonhorst.github.io/palmerpenguins/reference/penguins.html) by Allison Horst, Alison Hill and Kristen Gorman

* [R and SQLite](https://www.r-bloggers.com/2012/11/r-and-sqlite-part-1/) from Sandy Muspratt - an example using relational educational data and tables for students, classes, and schools

* [Introduction to MySQL with R](https://programminghistorian.org/en/lessons/getting-started-with-mysql-using-r) from Jeff Blackadar - an example using MySQL and historical data from newspaper articles

* [Using MySQL with R](https://jagg19.github.io/2019/05/mysql-r/) from Jagger Villalobos - an example using MySQL and a large Chicago Parking Ticket dataset 

* [Using SQL in RStudio](https://irene.rbind.io/post/using-sql-in-rstudio/) from Irene Steves - a discussion of the Rubymine IDE and working with SQL in RStudio, 

* [Creating, Writing, Querying, and Modifying SQL Database from R using odbc, dbplyr, and DBI](https://tbradley1013.github.io/2017/08/26/sql-management-in-r/) from Tyler Bradley


